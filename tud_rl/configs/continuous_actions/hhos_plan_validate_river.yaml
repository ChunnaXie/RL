---
env:
  name: HHOS-PathPlanning-Validation-v0
  max_episode_steps: 100
  state_type: feature
  wrappers: []
  wrapper_kwargs: {}
  env_kwargs:
    plan_on_river: true
    data: sampled
    state_design: recursive
    river_curve: right
    scenario: 1
  info: 
agent:
  DDPG: {}
  TD3:
    tgt_noise: 0.2
    tgt_noise_clip: 0.5
    pol_upd_delay: 2
  LSTMDDPG:
    history_length: 2
    use_past_actions: false
  LSTMTD3:
    tgt_noise: 0.2
    tgt_noise_clip: 0.5
    pol_upd_delay: 2
    history_length: 2
    use_past_actions: false
  LSTMRecTD3_a:
    tgt_noise: 0.2
    tgt_noise_clip: 0.5
    pol_upd_delay: 2
    history_length: 2
    use_past_actions: false
    num_obs_OS: 13
    num_obs_TS: 7
  LSTMRecTD3_b:
    tgt_noise: 0.2
    tgt_noise_clip: 0.5
    pol_upd_delay: 2
    history_length: 2
    use_past_actions: false
    num_obs_OS: 3
    num_obs_TS: 6
  SAC:
    lr_temp: 0.0001
    temp_tuning: true
    init_temp: 0.2
  LSTMSAC:
    history_length: 2
    use_past_actions: false
    lr_temp: 0.0001
    temp_tuning: true
    init_temp: 0.2
  TQC:
    lr_temp: 0.0001
    temp_tuning: true
    init_temp: 0.2
    top_qs_to_drop: 10
    n_qs: 25
    n_critics: 5
seed: 12
timesteps: 10_000_000
epoch_length: 5000
eval_episodes: 1
actor_weights: river_actor_60.pth
critic_weights: river_critic_60.pth
gamma: 0.99
tau: 0.001
net_struc_actor:
net_struc_critic:
optimizer: Adam
loss: MSELoss
lr_actor: 0.0001
lr_critic: 0.0001
buffer_length: 500_000
grad_clip: false
grad_rescale: false
act_start_step: 5000
upd_start_step: 5000
upd_every: 1
batch_size: 32
device: cpu
